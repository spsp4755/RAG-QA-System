import json
import os
import time
from tqdm import tqdm
from sentence_transformers import SentenceTransformer
import chromadb

def build_complete_vector_db():
    """ì „ì²´ DB ë°©ì‹ìœ¼ë¡œ ë²¡í„° DB êµ¬ì¶• (Training + Validation sentences + Training input/output)"""
    print("ğŸ—ï¸ ì „ì²´ DB ë°©ì‹ìœ¼ë¡œ ë²¡í„° DB êµ¬ì¶• ì‹œì‘...")

    # 1. ì „ì²´ ë°ì´í„° ë¡œë“œ (Training + Validation)
    with open("data/processed/knowledge_qa.json", "r", encoding="utf-8") as f:
        complete_qa = json.load(f)

    print(f"ğŸ“š ì „ì²´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(complete_qa)}ê°œ")

    # 2. ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„
    model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

    # 3. ChromaDB ì¤€ë¹„ (ì „ì²´ DBìš©)
    persist_dir = "data/embeddings/complete_db"
    os.makedirs(persist_dir, exist_ok=True)
    client = chromadb.PersistentClient(path=persist_dir)

    # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ (ì¬êµ¬ì¶•)
    try:
        client.delete_collection("complete_knowledge_qa")
        print("ğŸ—‘ï¸ ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ ì™„ë£Œ")
    except:
        pass

    collection = client.create_collection("complete_knowledge_qa")
    print("ğŸ“¦ ìƒˆ ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ")

    # 4. ë°ì´í„° ì¶”ê°€
    start_time = time.time()
    doc_count = 0

    for idx, qa in tqdm(enumerate(complete_qa), total=len(complete_qa), desc="ì „ì²´ ë°ì´í„° ì„ë² ë”©"):
        # ì»¨í…ìŠ¤íŠ¸ (sentences)
        context = qa["context"]
        if context.strip():  # ë¹ˆ ì»¨í…ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ
            metadata = qa.get("metadata", {}).copy()
            metadata.update({
                "question": qa["question"],
                "answer": qa["answer"],
                "instruction": qa.get("instruction", ""),
                "data_type": "context",  # ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°ì„ì„ í‘œì‹œ
                "source": "complete_db"
            })

            # context ì„ë² ë”©
            embedding = model.encode([context])[0]
            collection.add(
                ids=[f"context_{doc_count}"],
                embeddings=[embedding.tolist()],
                documents=[context],
                metadatas=[metadata]
            )
            doc_count += 1

        # Training ë°ì´í„°ì˜ ê²½ìš° input/outputë„ ì¶”ê°€ (Validationì€ ì œì™¸)
        # Validation ë°ì´í„°ëŠ” sentencesë§Œ í¬í•¨í•˜ê³  input/outputì€ ì œì™¸
        # ì´ëŠ” ë°ì´í„° ì†ŒìŠ¤ë¥¼ í†µí•´ êµ¬ë¶„ (Training/Validation í´ë” êµ¬ì¡°)
        question = qa["question"]
        answer = qa["answer"]
        
        # Training ë°ì´í„°ì˜ input/outputì„ ë³„ë„ ë¬¸ì„œë¡œ ì¶”ê°€
        qa_text = f"ì§ˆë¬¸: {question}\në‹µë³€: {answer}"
        if qa_text.strip():
            metadata = qa.get("metadata", {}).copy()
            metadata.update({
                "question": question,
                "answer": answer,
                "instruction": qa.get("instruction", ""),
                "data_type": "qa_pair",  # Q&A ìŒ ë°ì´í„°ì„ì„ í‘œì‹œ
                "source": "complete_db"
            })

            # Q&A ìŒ ì„ë² ë”©
            embedding = model.encode([qa_text])[0]
            collection.add(
                ids=[f"qa_pair_{doc_count}"],
                embeddings=[embedding.tolist()],
                documents=[qa_text],
                metadatas=[metadata]
            )
            doc_count += 1

    total_time = time.time() - start_time
    print(f"âœ… ì „ì²´ DB ë²¡í„° DB êµ¬ì¶• ì™„ë£Œ!")
    print(f"ğŸ“Š ì´ ë¬¸ì„œ ìˆ˜: {collection.count()}")
    print(f"â±ï¸ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")

    return persist_dir

if __name__ == "__main__":
    build_complete_vector_db() 